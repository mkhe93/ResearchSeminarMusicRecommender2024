{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of the Best Parameter Settings\n",
    "\n",
    "- take the best parameter settings for each algorithm out of the parameter search\n",
    "- run each algorithm on a given number of evaluation users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.9.19 | packaged by conda-forge | (main, Mar 20 2024, 12:38:46) [MSC v.1929 64 bit (AMD64)] on win32\n",
      "Project directory:  C:\\Users\\s8347434\\Documents\\RecSys2024\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# setting proper working directory\n",
    "PROJECT_DIRECTORY = Path(os.path.abspath('')).resolve().parents[0]\n",
    "sys.path.extend([str(PROJECT_DIRECTORY)])\n",
    "\n",
    "print(f'Python {sys.version} on {sys.platform}')\n",
    "print('Project directory: ', PROJECT_DIRECTORY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s8347434\\.conda\\envs\\recsys\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from implicit.evaluation import leave_k_out_split\n",
    "from src.utilities.Helper import load_data, create_sparse_matrix, train_test_split\n",
    "from src.utilities.MfAlgorithms import MFAlgorithms, MatrixFactorizationRecommender\n",
    "from src.utilities.NeighborAlgorithms import NeighborhoodAlgorithms, NeighborhoodRecommender\n",
    "from src.utilities.NonPersonalizedAlgorithms import NonPersonalizedAlgorithms, NonPersonalizedRecommender\n",
    "from src.utilities.Metrics import Evaluation, Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILENAME = PROJECT_DIRECTORY / \"data/processed/user_item_interaction_FILTERED_ANONYMIZED.txt\"\n",
    "DATASET = \"real\"\n",
    "ROWS = None\n",
    "TRAIN_TEST_SPLIT_STRATEGY = 42\n",
    "FOLDS = 5\n",
    "temp_list = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Read Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17665904, 2)\n",
      "Index(['userID', 'itemID'], dtype='object')\n",
      "Number of (users, items):  (58747, 37370)\n",
      "17665904\n",
      "Matrix sparsity: 0.8%\n"
     ]
    }
   ],
   "source": [
    "db_interaction = load_data(FILENAME, rows = ROWS, dataset=DATASET)\n",
    "print(db_interaction.shape)\n",
    "print(db_interaction.keys())\n",
    "\n",
    "if ROWS is not None:\n",
    "    # ONLY FOR SUBSETS: drop users below median interactions\n",
    "    threshold = np.median(db_interaction['userID'].value_counts())\n",
    "    print(\"Median user interactions: \", threshold)\n",
    "    # for manual values to remove\n",
    "    threshold = 20\n",
    "    filter_users = db_interaction['userID'].value_counts() >= threshold\n",
    "    filter_users = filter_users[filter_users].index.tolist()\n",
    "\n",
    "    db_interaction = db_interaction[db_interaction['userID'].isin(filter_users)].reset_index(drop=True)\n",
    "    print(\"The new size is: \", db_interaction.shape)\n",
    "\n",
    "sparse_user_item_interaction, user_index, item_index = create_sparse_matrix(db_interaction, dataset=DATASET)\n",
    "\n",
    "print(\"Number of (users, items): \", sparse_user_item_interaction.shape)\n",
    "\n",
    "print(sparse_user_item_interaction.getnnz())\n",
    "\n",
    "n_total = sparse_user_item_interaction.shape[0]*sparse_user_item_interaction.shape[1]\n",
    "n_ratings = sparse_user_item_interaction.nnz\n",
    "sparsity = n_ratings/n_total\n",
    "print(f\"Matrix sparsity: {round(sparsity*100,2)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Split Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_set, test_set = train_test_split(sparse_user_item_interaction, user_index, item_index, train_percentage=0.8, k=FOLDS, split_strategy=TRAIN_TEST_SPLIT_STRATEGY)\n",
    "train_set, test_set = leave_k_out_split(sparse_user_item_interaction, K=10, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "#np.random.seed(2)\n",
    "NUMB_EVAL_USERS = 100\n",
    "EVAL_USERS_LIST = []\n",
    "TOP_N = 10\n",
    "for n_eval_users in [100, 100, 100, 100, 100]:\n",
    "    if NUMB_EVAL_USERS == sparse_user_item_interaction.shape[0]:\n",
    "        EVAL_USERS = user_index.cat.categories\n",
    "    else:\n",
    "        EVAL_USERS = np.random.choice(user_index.cat.categories, n_eval_users, replace=False)\n",
    "        EVAL_USERS_IDX = [user_index.cat.codes[user_index==user].unique()[0] for user in EVAL_USERS]\n",
    "    # print(f'CustomerIDs: {EVAL_USERS}')\n",
    "    if TRAIN_TEST_SPLIT_STRATEGY == \"cross-fold\":\n",
    "        print(f'Total downloads per customer: {sparse_user_item_interaction[EVAL_USERS_IDX].getnnz(axis=1)}')\n",
    "        for fold in range(FOLDS):\n",
    "            print(f'Total downloads per customer in train: {train_set[fold][EVAL_USERS_IDX].getnnz(axis=1)}')\n",
    "            print(f'Total downloads per customer in test: {test_set[fold][EVAL_USERS_IDX].getnnz(axis=1)}')\n",
    "    else:\n",
    "        pass\n",
    "        #print(f'Total downloads per customer: {sparse_user_item_interaction[EVAL_USERS_IDX].getnnz(axis=1)}')\n",
    "        #print(f'Total downloads per customer in train: {train_set[EVAL_USERS_IDX].getnnz(axis=1)}')\n",
    "        #print(f'Total downloads per customer in test: {test_set[EVAL_USERS_IDX].getnnz(axis=1)}')\n",
    "    EVAL_USERS_LIST.append(EVAL_USERS)\n",
    "\n",
    "    print(len(EVAL_USERS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Read Parameter Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Evaluator  MatchCount  Precision    MR       MRR       MAP  \\\n",
      "0  ALSMatrixFactorization          95      0.095  0.55  0.278607  0.221468   \n",
      "1  ALSMatrixFactorization          98      0.098  0.56  0.288440  0.221122   \n",
      "\n",
      "       NDCG  Coverage   APLT       ARP    a  regularization  factors  \\\n",
      "0  0.340508  0.010749  0.002  3609.005  1.0             1.0       65   \n",
      "1  0.339124  0.021212  0.012  1630.747  1.2             1.0      300   \n",
      "\n",
      "   iterations  learning_rate  alpha    q  neighborhood_size  beta  \n",
      "0          10            0.0    0.0  0.0                  0   0.0  \n",
      "1          10            0.0    0.0  0.0                  0   0.0  \n",
      "(15, 19)\n"
     ]
    }
   ],
   "source": [
    "filename = PROJECT_DIRECTORY / \"data/evaluation/best3_parameter_settings.txt\"\n",
    "best3_parameter_settings = pd.read_csv(filename, sep=\"\\t\", encoding=\"utf-16\", dtype={\"factors\": \"Int64\", \"neighborhood_size\": \"Int64\", \"iterations\": \"Int64\"})\n",
    "\n",
    "print(best3_parameter_settings.head(2))\n",
    "print(best3_parameter_settings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "als_top3_parameter_settings = []\n",
    "bpr_top3_parameter_settings = []\n",
    "user_knn_top3_parameter_settings = []\n",
    "item_asym_knn_top3_parameter_settings = []\n",
    "user_asym_knn_top3_parameter_settings = []\n",
    "\n",
    "for i, row in best3_parameter_settings.iterrows():\n",
    "    if row[\"Evaluator\"] == \"ALSMatrixFactorization\":\n",
    "        als_top3_parameter_settings.append({\"a\": row[\"a\"], \"factors\": row[\"factors\"], \"regularization\": row[\"regularization\"], \"iterations\": row[\"iterations\"]})\n",
    "    elif row[\"Evaluator\"] == \"BPRMatrixFactorization\":\n",
    "        bpr_top3_parameter_settings.append({\"factors\": row[\"factors\"], \"regularization\": row[\"regularization\"], \"iterations\": row[\"iterations\"], \"learning_rate\": row[\"learning_rate\"]})\n",
    "    elif row[\"Evaluator\"] == \"UserKNN\":\n",
    "        user_knn_top3_parameter_settings.append({\"alpha\": row[\"alpha\"], \"q\": row[\"q\"], \"neighborhood_size\": row[\"neighborhood_size\"]})\n",
    "    elif row[\"Evaluator\"] == \"ItemIterativeAsymKNN\":\n",
    "        item_asym_knn_top3_parameter_settings.append({\"alpha\": row[\"alpha\"], \"beta\": row[\"beta\"], \"q\": row[\"q\"], \"neighborhood_size\": row[\"neighborhood_size\"]})\n",
    "    elif row[\"Evaluator\"] == \"UserIterativeAsymKNN\":\n",
    "        user_asym_knn_top3_parameter_settings.append({\"alpha\": row[\"alpha\"], \"beta\": row[\"beta\"], \"q\": row[\"q\"], \"neighborhood_size\": row[\"neighborhood_size\"]})\n",
    "\n",
    "step = len(user_knn_top3_parameter_settings) * len(EVAL_USERS_LIST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Start Test Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of metrics to apply\n",
    "metrics_list = ['MatchCount', 'Precision', 'MR', 'MRR', 'MAP', 'NDCG','Coverage', 'APLT', 'ARP']\n",
    "\n",
    "# Instantiate the Evaluation class\n",
    "evaluator = Evaluation(Metrics, sparse_user_item_interaction)\n",
    "\n",
    "# Add metrics from the Metrics class\n",
    "for metric in metrics_list:\n",
    "    evaluator.add_metric(metric)\n",
    "\n",
    "def evaluate(evaluators_predictions):# Evaluate metrics for each evaluator and store results\n",
    "    results = []\n",
    "    for evaluator_name, recommendations in evaluators_predictions.items():\n",
    "        result = {\n",
    "            'Evaluator': evaluator_name,\n",
    "            'MatchCount': evaluator.evaluate('MatchCount', recommendations, test_set, user_index, item_index),\n",
    "            'Precision': evaluator.evaluate('Precision', recommendations, test_set, user_index, item_index),\n",
    "            'MR': evaluator.evaluate('MR', recommendations, test_set, user_index, item_index),\n",
    "            'MRR': evaluator.evaluate('MRR', recommendations, test_set, user_index, item_index),\n",
    "            'MAP': evaluator.evaluate('MAP', recommendations, test_set, user_index, item_index),\n",
    "            'NDCG': evaluator.evaluate('NDCG', recommendations, test_set, user_index, item_index),\n",
    "            'Coverage': evaluator.evaluate('Coverage', recommendations, test_set, user_index, item_index, threshold=\"Median\"),\n",
    "            'APLT': evaluator.evaluate('APLT', recommendations, test_set, user_index, item_index),\n",
    "            'ARP': evaluator.evaluate('ARP', recommendations, test_set, user_index, item_index),\n",
    "            'n_users': recommendations.shape[0],\n",
    "            'top_N': len(recommendations['itemID'][0])\n",
    "        }\n",
    "        results.append(result)\n",
    "\n",
    "    # Create a DataFrame from the results\n",
    "    df = pd.DataFrame(results)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NonPersonalizedRecommender(NonPersonalizedAlgorithms)\n",
    "model.add_algorithm('most_popular')\n",
    "model.fit(user_item_matrix=train_set)\n",
    "i = 1\n",
    "temp_list = []\n",
    "for eval_users in EVAL_USERS_LIST:\n",
    "    Recoms = model.recommend(eval_users, user_index, item_index, TOP_N, already_interacted=[])\n",
    "    evaluators_predictions = {'MostPop': Recoms}\n",
    "    temp_df = evaluate(evaluators_predictions)\n",
    "    temp_list.append(temp_df)\n",
    "    i += 1\n",
    "    print(f\"Progress: {i/len(EVAL_USERS_LIST) *100:.2f}%\")\n",
    "    \n",
    "most_pop_results_df = pd.concat(temp_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# most_pop_results_df.to_csv(f\"../data/evaluation/test_runs/real_life_MostPop_evaluation_{len(EVAL_USERS_LIST[0])}EVAL-USERS_TOP-{TOP_N}_{sparse_user_item_interaction.getnnz()}ROWS.txt\", sep=\"\\t\", encoding='utf-16', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MatrixFactorizationRecommender(MFAlgorithms)\n",
    "model.add_algorithm('als_algorithm')\n",
    "i = 1\n",
    "temp_list = []\n",
    "for parameter_setting in als_top3_parameter_settings:\n",
    "        model.fit(user_item_matrix=train_set, factors=parameter_setting[\"factors\"], regularization=parameter_setting[\"regularization\"], alpha=parameter_setting[\"a\"], iterations=parameter_setting[\"iterations\"], random_state=42)\n",
    "        print(f\"Progress: {i/step *100:.2f}%\")\n",
    "        for eval_users in EVAL_USERS_LIST:\n",
    "            print(f\"Progress: {i/step *100:.2f}%\")\n",
    "            Recoms = model.recommend(eval_users, train_set, user_index, item_index, TOP_N)\n",
    "            evaluators_predictions = {'ALSMatrixFactorization': Recoms}\n",
    "            temp_df = evaluate(evaluators_predictions)\n",
    "            temp_list.append(temp_df)\n",
    "            i += 1\n",
    "            print(f\"Progress: {i/step *100:.2f}%\")\n",
    "\n",
    "als_results_df = pd.concat(temp_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# als_results_df.to_csv(f\"../data/evaluation/test_runs/real_life_ALS_evaluation_{len(EVAL_USERS_LIST[0])}EVAL-USERS_TOP-{TOP_N}_{sparse_user_item_interaction.getnnz()}ROWS.txt\", sep=\"\\t\", encoding='utf-16', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeighborhoodRecommender(NeighborhoodAlgorithms)\n",
    "model.add_algorithm('user_based_neighborhood')\n",
    "i = 1\n",
    "temp_list = []\n",
    "for parameter_setting in user_knn_top3_parameter_settings:\n",
    "    model.fit(user_item_matrix=train_set, alpha=parameter_setting[\"alpha\"], q=parameter_setting[\"q\"])\n",
    "    for eval_users in EVAL_USERS_LIST:\n",
    "        Recoms = model.recommend(eval_users, train_set, user_index, item_index, TOP_N, neighborhood_size=parameter_setting[\"neighborhood_size\"], already_interacted=[])\n",
    "        print(f\"Progress: {i/step *100:.2f}%\")\n",
    "        evaluators_predictions = {'UserKNN': Recoms}\n",
    "        temp_df = evaluate(evaluators_predictions)\n",
    "        temp_list.append(temp_df)\n",
    "        i += 1\n",
    "        print(f\"Progress: {i/step *100:.2f}%\")\n",
    "\n",
    "user_knn_results_df = pd.concat(temp_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_knn_results_df.to_csv(f\"../data/evaluation/test_runs/real_life_UserKNN_evaluation_{len(EVAL_USERS_LIST[0])}EVAL-USERS_TOP-{TOP_N}_{sparse_user_item_interaction.getnnz()}ROWS.txt\", sep=\"\\t\", encoding='utf-16', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeighborhoodRecommender(NeighborhoodAlgorithms)\n",
    "model.add_algorithm('user_based_iterative_asym_neighborhood')\n",
    "i = 1\n",
    "temp_list = []\n",
    "for parameter_setting in user_asym_knn_top3_parameter_settings:\n",
    "    model.fit(user_item_matrix=train_set, alpha=parameter_setting[\"alpha\"], q=parameter_setting[\"q\"])\n",
    "    for eval_users in EVAL_USERS_LIST:\n",
    "        Recoms = model.recommend(eval_users, train_set, user_index, item_index, TOP_N, neighborhood_size=parameter_setting[\"neighborhood_size\"], beta=parameter_setting[\"beta\"], already_interacted=[])\n",
    "        print(f\"Progress: {i/step *100:.2f}%\")\n",
    "        evaluators_predictions = {'UserAsymKNN': Recoms}\n",
    "        temp_df = evaluate(evaluators_predictions)\n",
    "        temp_list.append(temp_df)\n",
    "        i += 1\n",
    "        print(f\"Progress: {i/step *100:.2f}%\")\n",
    "\n",
    "user_asym_knn_results_df = pd.concat(temp_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_asym_knn_results_df.to_csv(f\"../data/evaluation/test_runs/real_life_UserAsymKNN_evaluation_{len(EVAL_USERS_LIST[0])}EVAL-USERS_TOP-{TOP_N}_{sparse_user_item_interaction.getnnz()}ROWS.txt\", sep=\"\\t\", encoding='utf-16', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeighborhoodRecommender(NeighborhoodAlgorithms)\n",
    "model.add_algorithm('item_based_iterative_asym_neighborhood')\n",
    "i = 1\n",
    "temp_list = []\n",
    "for parameter_setting in item_asym_knn_top3_parameter_settings:\n",
    "    model.fit(user_item_matrix=train_set, alpha=parameter_setting[\"alpha\"], q=parameter_setting[\"q\"])\n",
    "    for eval_users in EVAL_USERS_LIST:\n",
    "        Recoms = model.recommend(eval_users, train_set, user_index, item_index, TOP_N, neighborhood_size=parameter_setting[\"neighborhood_size\"], beta=parameter_setting[\"beta\"], already_interacted=[])\n",
    "        print(f\"Progress: {i/step *100:.2f}%\")\n",
    "        evaluators_predictions = {'ItemAsymKNN': Recoms}\n",
    "        temp_df = evaluate(evaluators_predictions)\n",
    "        temp_list.append(temp_df)\n",
    "        i += 1\n",
    "        print(f\"Progress: {i/step *100:.2f}%\")\n",
    "\n",
    "item_asym_knn_results_df = pd.concat(temp_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# item_asym_knn_results_df.to_csv(f\"../data/evaluation/test_runs/real_life_ItemAsymKNN_evaluation_{len(EVAL_USERS_LIST[0])}EVAL-USERS_TOP-{TOP_N}_{sparse_user_item_interaction.getnnz()}ROWS.txt\", sep=\"\\t\", encoding='utf-16', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Evaluate the Test Run Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the test run files for each algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Evaluator  MatchCount  Precision    MR       MRR       MAP      NDCG  \\\n",
      "0   MostPop           8      0.008  0.08  0.023512  0.023512  0.036422   \n",
      "1   MostPop          15      0.015  0.14  0.074500  0.073548  0.090396   \n",
      "\n",
      "   Coverage  APLT        ARP  n_users  top_N  \n",
      "0  0.001124   0.0  12450.011      100     10  \n",
      "1  0.001204   0.0  12427.732      100     10  \n",
      "(65, 12)\n"
     ]
    }
   ],
   "source": [
    "n_users = 100\n",
    "top_n = 10\n",
    "rows = 17665904\n",
    "eval_algorithms = [\"MostPop\", \"ALS\", \"UserKNN\", \"UserAsymKNN\", \"ItemAsymKNN\"]\n",
    "\n",
    "temp_list = []\n",
    "for algorithm in eval_algorithms:\n",
    "    filename = PROJECT_DIRECTORY / f\"data/evaluation/test_runs/real_life_{algorithm}_evaluation_{n_users}EVAL-USERS_TOP-{top_n}_{rows}ROWS.txt\"\n",
    "    temp_df = pd.read_csv(filename, sep=\"\\t\", encoding=\"utf-16\")\n",
    "    temp_list.append(temp_df)\n",
    "\n",
    "overall_eval_df = pd.concat(temp_list)\n",
    "print(overall_eval_df.head(2))\n",
    "print(overall_eval_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the best $N$ values for each algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\s8347434\\AppData\\Local\\Temp\\5\\ipykernel_48060\\3945932269.py:3: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  overall_eval_df.groupby('Evaluator').apply(lambda x: x.nlargest(N, 'NDCG')).reset_index(drop=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Evaluator</th>\n",
       "      <th>MatchCount</th>\n",
       "      <th>Precision</th>\n",
       "      <th>MR</th>\n",
       "      <th>MRR</th>\n",
       "      <th>MAP</th>\n",
       "      <th>NDCG</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>APLT</th>\n",
       "      <th>ARP</th>\n",
       "      <th>n_users</th>\n",
       "      <th>top_N</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ALSMatrixFactorization</td>\n",
       "      <td>130</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.394706</td>\n",
       "      <td>0.284739</td>\n",
       "      <td>0.437889</td>\n",
       "      <td>0.017982</td>\n",
       "      <td>0.000</td>\n",
       "      <td>4669.812</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ItemAsymKNN</td>\n",
       "      <td>71</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.247579</td>\n",
       "      <td>0.213313</td>\n",
       "      <td>0.300595</td>\n",
       "      <td>0.006369</td>\n",
       "      <td>0.010</td>\n",
       "      <td>9651.946</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MostPop</td>\n",
       "      <td>15</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.074500</td>\n",
       "      <td>0.073548</td>\n",
       "      <td>0.090396</td>\n",
       "      <td>0.001204</td>\n",
       "      <td>0.000</td>\n",
       "      <td>12427.732</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UserAsymKNN</td>\n",
       "      <td>104</td>\n",
       "      <td>0.104</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.312413</td>\n",
       "      <td>0.233236</td>\n",
       "      <td>0.357557</td>\n",
       "      <td>0.015039</td>\n",
       "      <td>0.000</td>\n",
       "      <td>5684.484</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UserKNN</td>\n",
       "      <td>112</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.329591</td>\n",
       "      <td>0.258861</td>\n",
       "      <td>0.400839</td>\n",
       "      <td>0.014075</td>\n",
       "      <td>0.004</td>\n",
       "      <td>6119.892</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Evaluator  MatchCount  Precision    MR       MRR       MAP  \\\n",
       "0  ALSMatrixFactorization         130      0.130  0.63  0.394706  0.284739   \n",
       "1             ItemAsymKNN          71      0.071  0.49  0.247579  0.213313   \n",
       "2                 MostPop          15      0.015  0.14  0.074500  0.073548   \n",
       "3             UserAsymKNN         104      0.104  0.55  0.312413  0.233236   \n",
       "4                 UserKNN         112      0.112  0.65  0.329591  0.258861   \n",
       "\n",
       "       NDCG  Coverage   APLT        ARP  n_users  top_N  \n",
       "0  0.437889  0.017982  0.000   4669.812      100     10  \n",
       "1  0.300595  0.006369  0.010   9651.946      100     10  \n",
       "2  0.090396  0.001204  0.000  12427.732      100     10  \n",
       "3  0.357557  0.015039  0.000   5684.484      100     10  \n",
       "4  0.400839  0.014075  0.004   6119.892      100     10  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 1\n",
    "\n",
    "overall_eval_df.groupby('Evaluator').apply(lambda x: x.nlargest(N, 'NDCG')).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aggregate the best $N$ values by it's mean.\n",
    "\n",
    "> These values correspond to the ones in the seminar paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\s8347434\\AppData\\Local\\Temp\\5\\ipykernel_48060\\3295011710.py:3: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  best_eval_df = overall_eval_df.groupby('Evaluator').apply(lambda x: x.nlargest(N, 'NDCG')).reset_index(drop=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Evaluator</th>\n",
       "      <th>MatchCount</th>\n",
       "      <th>Precision</th>\n",
       "      <th>MR</th>\n",
       "      <th>MRR</th>\n",
       "      <th>MAP</th>\n",
       "      <th>NDCG</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>APLT</th>\n",
       "      <th>ARP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ALSMatrixFactorization</td>\n",
       "      <td>115.8</td>\n",
       "      <td>0.1158</td>\n",
       "      <td>0.608</td>\n",
       "      <td>0.358633</td>\n",
       "      <td>0.264218</td>\n",
       "      <td>0.403916</td>\n",
       "      <td>0.016634</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>5179.8074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ItemAsymKNN</td>\n",
       "      <td>64.2</td>\n",
       "      <td>0.0642</td>\n",
       "      <td>0.460</td>\n",
       "      <td>0.237421</td>\n",
       "      <td>0.203494</td>\n",
       "      <td>0.283813</td>\n",
       "      <td>0.005823</td>\n",
       "      <td>0.0104</td>\n",
       "      <td>9836.3442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MostPop</td>\n",
       "      <td>11.8</td>\n",
       "      <td>0.0118</td>\n",
       "      <td>0.108</td>\n",
       "      <td>0.043048</td>\n",
       "      <td>0.042225</td>\n",
       "      <td>0.057969</td>\n",
       "      <td>0.001054</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>12477.9728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UserAsymKNN</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0.0980</td>\n",
       "      <td>0.514</td>\n",
       "      <td>0.284855</td>\n",
       "      <td>0.210499</td>\n",
       "      <td>0.329470</td>\n",
       "      <td>0.016157</td>\n",
       "      <td>0.0164</td>\n",
       "      <td>5299.9964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UserKNN</td>\n",
       "      <td>111.8</td>\n",
       "      <td>0.1118</td>\n",
       "      <td>0.636</td>\n",
       "      <td>0.328724</td>\n",
       "      <td>0.254424</td>\n",
       "      <td>0.393336</td>\n",
       "      <td>0.015403</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>5830.9746</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Evaluator  MatchCount  Precision     MR       MRR       MAP  \\\n",
       "0  ALSMatrixFactorization       115.8     0.1158  0.608  0.358633  0.264218   \n",
       "1             ItemAsymKNN        64.2     0.0642  0.460  0.237421  0.203494   \n",
       "2                 MostPop        11.8     0.0118  0.108  0.043048  0.042225   \n",
       "3             UserAsymKNN        98.0     0.0980  0.514  0.284855  0.210499   \n",
       "4                 UserKNN       111.8     0.1118  0.636  0.328724  0.254424   \n",
       "\n",
       "       NDCG  Coverage    APLT         ARP  \n",
       "0  0.403916  0.016634  0.0000   5179.8074  \n",
       "1  0.283813  0.005823  0.0104   9836.3442  \n",
       "2  0.057969  0.001054  0.0000  12477.9728  \n",
       "3  0.329470  0.016157  0.0164   5299.9964  \n",
       "4  0.393336  0.015403  0.0020   5830.9746  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 5\n",
    "\n",
    "best_eval_df = overall_eval_df.groupby('Evaluator').apply(lambda x: x.nlargest(N, 'NDCG')).reset_index(drop=True)\n",
    "\n",
    "best_eval_df.groupby('Evaluator').agg({\n",
    "    'MatchCount': 'mean',\n",
    "    'Precision': 'mean',\n",
    "    'MR': 'mean',\n",
    "    'MRR': 'mean',\n",
    "    'MAP': 'mean',\n",
    "    'NDCG': 'mean',\n",
    "    'Coverage': 'mean',\n",
    "    'APLT': 'mean',\n",
    "    'ARP': 'mean'\n",
    "}).reset_index()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recsys",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
